From 541eb14af87e6de3cc136876bc8c14eddc389dba Mon Sep 17 00:00:00 2001
From: stanus74 <holger.freier@gmail.com>
Date: Fri, 30 Jan 2026 08:19:22 +0100
Subject: [PATCH 5/7] Flash-Attention: AMD-Wave32 Fix & gfx906-Q8-Pfad

---
 ggml/src/ggml-cuda/fattn-common.cuh | 11 ++++++--
 ggml/src/ggml-cuda/fattn.cu         | 41 ++++++++++++++++++++++++++---
 2 files changed, 47 insertions(+), 5 deletions(-)

diff --git a/ggml/src/ggml-cuda/fattn-common.cuh b/ggml/src/ggml-cuda/fattn-common.cuh
index b6a7460d..b982bd6d 100644
--- a/ggml/src/ggml-cuda/fattn-common.cuh
+++ b/ggml/src/ggml-cuda/fattn-common.cuh
@@ -276,8 +276,8 @@ static __device__ __forceinline__ void quantize_q8_1_to_shared(
     }
 #pragma unroll
     for (int mask = QI8_1/2; mask > 0; mask >>= 1) {
-        amax = fmaxf(amax, __shfl_xor_sync(0xFFFFFFFF, amax, mask, 32));
-        sum +=             __shfl_xor_sync(0xFFFFFFFF, sum,  mask, 32);
+        amax = fmaxf(amax, ggml_cuda_shfl_xor_sync<32>(amax, mask));
+        sum +=             ggml_cuda_shfl_xor_sync<32>(sum,  mask);
     }
 
     const float d = amax / 127;
@@ -965,6 +965,13 @@ void launch_fattn(
             }
         }
 
+        const bool is_amd = !GGML_CUDA_CC_IS_NVIDIA(cc);
+        const bool is_prompt_processing = Q->ne[1] > 1;
+
+        if (is_amd && is_prompt_processing) {
+            parallel_blocks = 1;
+        }
+
         blocks_num.x = ntiles_x;
         blocks_num.y = parallel_blocks;
         blocks_num.z = ntiles_z_gqa*K->ne[2]*Q->ne[3];
diff --git a/ggml/src/ggml-cuda/fattn.cu b/ggml/src/ggml-cuda/fattn.cu
index 721edd99..c32c1ed0 100644
--- a/ggml/src/ggml-cuda/fattn.cu
+++ b/ggml/src/ggml-cuda/fattn.cu
@@ -1,3 +1,6 @@
+#include <cstdlib>
+#include <cstring>
+
 #include "common.cuh"
 #include "fattn-common.cuh"
 #include "fattn-mma-f16.cuh"
@@ -6,6 +9,10 @@
 #include "fattn-wmma-f16.cuh"
 #include "fattn.cuh"
 
+#ifdef GGML_USE_HIP
+#include "gfx906/gfx906-fattn-q8.cuh"
+#endif
+
 template <int DKQ, int DV, int ncols2>
 static void ggml_cuda_flash_attn_ext_mma_f16_switch_ncols1(ggml_backend_cuda_context & ctx, ggml_tensor * dst) {
     const int cc = ggml_cuda_info().devices[ggml_cuda_get_device()].cc;
@@ -273,6 +280,9 @@ enum best_fattn_kernel {
     BEST_FATTN_KERNEL_NONE     =   0,
     BEST_FATTN_KERNEL_TILE     = 200,
     BEST_FATTN_KERNEL_VEC      = 100,
+#ifdef GGML_USE_HIP
+    BEST_FATTN_KERNEL_TILE_Q8  = 250,
+#endif
     BEST_FATTN_KERNEL_WMMA_F16 = 300,
     BEST_FATTN_KERNEL_MMA_F16  = 400,
 };
@@ -297,9 +307,9 @@ static best_fattn_kernel ggml_cuda_get_best_fattn_kernel(const int device, const
 
     // The effective batch size for the kernel can be increased by gqa_ratio.
     // The kernel versions without this optimization are also used for ALiBi, if there is no mask, or if the KV cache is not padded,
-    bool gqa_opt_applies = gqa_ratio >= 2 && mask && max_bias == 0.0f && K->ne[1] % FATTN_KQ_STRIDE == 0;
+    bool gqa_opt_applies = gqa_ratio % 2 == 0 && mask && max_bias == 0.0f && K->ne[1] % FATTN_KQ_STRIDE == 0;
     for (const ggml_tensor * t : {Q, K, V, mask}) {
-        if (t == nullptr || ggml_is_quantized(t->type)) {
+        if (t == nullptr) {
             continue;
         }
         for (size_t i = 1; i < GGML_MAX_DIMS; ++i) {
@@ -448,12 +458,32 @@ static best_fattn_kernel ggml_cuda_get_best_fattn_kernel(const int device, const
                     return BEST_FATTN_KERNEL_VEC;
                 }
             }
-        } else {
+        }
+#ifndef GGML_USE_HIP
+        else {
             if (Q->ne[1] <= 2) {
                 return BEST_FATTN_KERNEL_VEC;
             }
         }
+#endif
+    }
+
+#ifdef GGML_USE_HIP
+    if (K->type == GGML_TYPE_Q8_0 || V->type == GGML_TYPE_Q8_0) {
+        const bool q8_head_size_supported = (K->ne[0] % 32 == 0) &&
+                                            (K->ne[0] != 40) &&
+                                            (K->ne[0] != 80) &&
+                                            (K->ne[0] != 112);
+
+        if (q8_head_size_supported) {
+            const char * env_use_dot4 = getenv("GGML_HIP_FATTN_USE_TILE_DOT4");
+            if (env_use_dot4 == nullptr || strcmp(env_use_dot4, "0") != 0) {
+                return BEST_FATTN_KERNEL_TILE_Q8;
+            }
+        }
     }
+#endif
+
     return BEST_FATTN_KERNEL_TILE;
 }
 
@@ -465,6 +495,11 @@ void ggml_cuda_flash_attn_ext(ggml_backend_cuda_context & ctx, ggml_tensor * dst
         case BEST_FATTN_KERNEL_TILE:
             ggml_cuda_flash_attn_ext_tile(ctx, dst);
             break;
+#ifdef GGML_USE_HIP
+        case BEST_FATTN_KERNEL_TILE_Q8:
+            ggml_cuda_flash_attn_ext_tile_q8(ctx, dst);
+            break;
+#endif
         case BEST_FATTN_KERNEL_VEC:
             ggml_cuda_flash_attn_ext_vec(ctx, dst);
             break;
-- 
2.52.0

